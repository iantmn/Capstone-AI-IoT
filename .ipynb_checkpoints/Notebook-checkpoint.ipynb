{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Machine learning for IDE students application!\n",
    "\n",
    "This is a JupyterNotebook created for IDE students to get started with machine learning for product analysation. This might be a lot at first and you might not have any programming background. If you follow the steps and read the explanation you should be able to use our machine-learning application. \n",
    "\n",
    "## Application\n",
    "\n",
    "This application will take you through the steps needed to be taken to analyse product usage using machine learning. It will not cover the data gathering, but we created a **different document** that shows how to collect data for your model and prepare it for usage in this program.\n",
    "\n",
    "In this program, we will follow a certain number of steps. We will briefly go over them so you understand the basics and further on we will explain them more:\n",
    "\n",
    "**The main flow of the program**\n",
    "\n",
    " 1. Preprocessing, preparing the data and making it ready for usage in the program. This step extracts the information(features) from the data that you've gathered, because the data is not quite usable in its raw state.\n",
    " 2. Active learning, the training part of the program. This part classifies the data you have gathered, but it needs your help. It will show you the video that you have made of the activity performed with the product and asks you to classify the action. This is why it is needed to video-capture the activities. It will update its model every time and that way it learns actively.\n",
    " 3. Usage after training, the part where you can gather the actual data about product usage. You have trained the model in the active learning step, now you can see the product usage. The model sees what action is performed and will see if something is being done that is not in the trained model, novelty detection.\n",
    "\n",
    "## key terms\n",
    "**Class** There are multiple classes for each model, a class is the \"bucket\" in which a datapoint belongs. You can see it as how it is classified.\n",
    "**Model**: A machine learning model that can predict in what class a datapoint belongs\n",
    "**Datapoint**: One point of data, the model sees this as one thing that enters the model.\n",
    "**Features** Features belong to a datapoint. A datapoint has multiple features most of the time.\n",
    "\n",
    "\n",
    "## Pre-processing\n",
    "The data you have gathered are accelerometer data and gyroscope data, if you do not know what these are, please consolidate this [video](https://www.youtube.com/watch?v=vFUlaRmuEHk&ab_channel=SymmetryElectronics).\n",
    "This data is used to train the model to detect that action is performed with the product, but this data is messy and can not be understood by the model as well. To get an understanding of this data.\n",
    "\n",
    "![accelerometer and gyroscope data explanation](https://www.researchgate.net/publication/335978678/figure/fig1/AS:806271687073792@1569241558268/Example-of-accelerometer-and-gyroscope-data-Data-from-several-activities-is.ppm)\n",
    "This looks like our data, but our data is not in a graph, but looks like **insert image of actual data**\n",
    "\n",
    "![enter image description here](https://www.electronicwings.com/storage/PlatformSection/TopicContent/311/description/Arduino_Output_window.png)\n",
    "\n",
    "As you might understand this is not readable that easily even for a machine, however when we do some calculations on this data we get new features about the data points. \n",
    "\n",
    "### The actual pre-processing\n",
    "To get an understanding of what happens. You need to know that we divide the data into frames, this way we can get a better sense of the data and be more certain of our prediction, because we use more raw data, moreover it makes the model faster. \n",
    "\n",
    "![enter image description here](https://www.researchgate.net/publication/346142883/figure/fig2/AS:961234023231491@1606187458853/Framing-raw-sensor-data-as-12-input-to-CNN-trained-to-predict-the-local-displacement-x.ppm)\n",
    "This shows how the data is framed and processed. \n",
    "We extract features from the frame like:\n",
    "*Note that this is per direction for the accelerometer and per axis for the gyroscope*\n",
    "\n",
    " - Average\n",
    " - Maximum\n",
    " - Minimum\n",
    " - Standard deviation\n",
    " - Most present frequency\n",
    "\n",
    "### Fourier Transform\n",
    "The last element of the feature list needs some extra explanation. We use a Fourier transformer to get more information on the frequencies that are in the data signal.\n",
    "most signals are composed in multiple frequencies like sound waves for example. A Fourier transformer can distinguish all these frequencies and then we can process all frequencies independently. It looks something like this:\n",
    "![enter image description here](https://www.nti-audio.com/portals/0/pic/news/FFT-Time-Frequency-View-540.png)\n",
    "\n",
    "## Lets Start\n",
    "There are 4 variables that are important for you to edit.\n",
    "\n",
    " - Frame size: The size of the frame used for the feature extraction, set larger for slow movements. Smaller for very quick movements. Standard = 2 sec.\n",
    " - Frame offset: The amount of offset per frame, can be increased is the window size is set bigger. \n",
    " - start-chop \n",
    " - end-chop\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Active learning\n",
    "\n",
    "If you have set up all your files and variables correctly this step should be quite easy. If all is right the application will show you a part of the video you have recorded with the question to label it according to the action performed on screen. If you need a new label because the correct option is not one of the options, you can add that. \n",
    "\n",
    "\n",
    "## Congratulations\n",
    "\n",
    "You have just trained a machine-learning model! The model is now trained to use for analysation of product usage. The model will predict the class that the movement of the real- world data is and can detect if something strange is happening. This will help you to create a better product.\n",
    "\n",
    "\n",
    "## Get you real world data\n",
    "\n",
    "In this step, you can insert your real-world data into the model. \n",
    "If there are any novelties they will show in the result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the packages\n",
    "To be able to run the application we need to import packages. \n",
    "These packages were mostly written by us and contain the main functions of the program, so this program does not look like a whole bunch of code. \n",
    "Packages are python code that can be imported, this way your code stays clean because the majority of the code is not in the current file, but in another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'type' and 'types.GenericAlias'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32732\\3835559064.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# from Data_Gathering_and_Preprocessing.data_processing import Preprocessing, empty_files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# from Model_Active_Learning.active_learning import ActiveLearning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mAI_for_Designers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_processing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPreprocessing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mempty_files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mAI_for_Designers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactive_learning\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mActiveLearning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mAI_for_Designers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnovelty_detection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNoveltyDetection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\Capstone-AI-IoT\\AI_for_Designers\\data_processing.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mPreprocessing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_ID\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_ID\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maction_ID\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\Capstone-AI-IoT\\AI_for_Designers\\data_processing.py\u001b[0m in \u001b[0;36mPreprocessing\u001b[1;34m()\u001b[0m\n\u001b[0;32m    191\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msampling_frequency\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_point\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m     def windowing(self, input_file: str | list[str], video_file: str = '', label: str = '',\n\u001b[0m\u001b[0;32m    194\u001b[0m                   \u001b[0mstart_offset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_offset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m                   \u001b[0msize\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'type' and 'types.GenericAlias'"
     ]
    }
   ],
   "source": [
    "# from Data_Gathering_and_Preprocessing.data_processing import Preprocessing, empty_files\n",
    "# from Model_Active_Learning.active_learning import ActiveLearning\n",
    "from __future__ import an\n",
    "from AI_for_Designers.data_processing import Preprocessing, empty_files\n",
    "from AI_for_Designers.active_learning import ActiveLearning\n",
    "from AI_for_Designers.novelty_detection import NoveltyDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Activity = 'Walking3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_files([f'Preprocessed-data/{Activity}/features_{Activity}.txt',\n",
    "             f'Preprocessed-data/{Activity}/features_{Activity}_scaled.csv',\n",
    "             f'Preprocessed-data/{Activity}/processed_data_files.txt'])\n",
    "\n",
    "pre = Preprocessing(Activity)\n",
    "pre.windowing([r\"Data/data-lopen/Walking_part_1.csv\", r\"Data/data-lopen/Walking_part_1_gyro.csv\"], r\"Data/data-lopen/Walking_part_1.mp4\",\n",
    "              start_offset=2.5, stop_offset=5, size=1, offset=0.2, epsilon=0.01, do_plot=False, do_scale=False)\n",
    "pre.windowing([r\"Data/data-lopen/Walking_part_2.csv\", r\"Data/data-lopen/Walking_part_2_gyro.csv\"], r\"Data/data-lopen/Walking_part_2.mp4\",\n",
    "              start_offset=2.5, stop_offset=5, size=1, offset=0.2, epsilon=0.01, do_plot=False, do_scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active learning\n",
    "\n",
    "If you have set up all your files and variables correctly this step should be quite easy. If all is right the application will show you a part of the video you have recorded with the question to label it according to the action performed on screen. \n",
    "\n",
    "Here you can enter the number of activities that you think will be in the video. If there are more than you antivipated in the first place, no problem, you can add them later. \n",
    "This is also the step where you train the model, take your time and label the data correctly, else, this will result in a bad model. There is also the option to delete a certain datapoint if you are not sure about something or if it is a faulty one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['walking', 'running', 'stairs_up', 'stairs_down']\n",
    "# vid = VideoLabeler(labels)\n",
    "# vid.labeling\n",
    "\n",
    "AL = ActiveLearning(fr'Preprocessed-data/{Activity}/features_{Activity}_scaled.csv', Activity, labels, 1)\n",
    "AL.training(5)\n",
    "AL.plotting()\n",
    "AL.write_to_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL.testing(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Congratulations\n",
    "\n",
    "You have just trained a machine-learning model! The model is now trained to use for analysation of product usage. The model will predict the class that the movement of the real- world data is and can detect if something strange is happening. This will help you to create a better product.\n",
    "\n",
    "\n",
    "## Get you real world data\n",
    "\n",
    "In this step, you can insert your real-world data into the model. \n",
    "If there are any novelties they will show in the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ND = NoveltyDetection(fr'Processed-data/{Activity}/features_{Activity}_scaled_AI_predictions')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "529ecdcae69add5700b168af870c2c245dc5754f1a82655f7b34366657b0a28f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
