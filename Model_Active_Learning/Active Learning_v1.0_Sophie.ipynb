{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit voorbeeld van https://towardsdatascience.com/active-learning-5b9d0955292d gaat over 3 subspecies classificeren\n",
    "<br>os voor mappen en content checken, imageio voor gifs (de rest is zoals we gewend zijn: numpy voor array manipulation, sklearn voor modellen, pandas voor data processen, plt voor plots en grafieken) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evt hyperparameter tuning moet hierna, dan doen wij wss model selection (beste model hangt meer af van sensor type dan data zelf) en worden de uiteindelijke training samples aan het einde van deze notebook lokaal opgeslagen om in een volgend notebook te gebruiken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import imageio as io\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier 2 features voor visualisatie (GIF!), wij kunnen dit nabootsen met PCA zou wel leuk zijn :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# Dit moet allemaal met preprocessed data! Lijkt mij handig om een aparte notebook te geven waarin ze dat doen\n",
    "# Ik laat nog wel een keertje de scribe pipeline zien daarmee kan je heel snel een guide met verwijzingen maken\n",
    "data = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy coderen:\n",
    "# Moet designer dit ook doen?! Makkelijker om ze zelf een legenda te laten bijhouden denk ik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De volgende stappen gebruiken een volledig gelabelde dataset! Wij hebben dit sowieso nodig voor model selection, en ik\n",
    "denk dat het wel goed is om in de rapportage te laten zien hoe het algoritme optimaliseert. en ziet er wel cool uit\n",
    "<br>Maar dit doet de designer dus juist niet! punt is dat ze als ze de andere stappen volgen echt maar heel weinig hoeven te labellen, en is ook niet foutgevoelig want ze doen het handmatig op alleen de nodige punten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discarded samples from 1 class\n",
    "X1 = X[y != 0]\n",
    "y1 = y[y != 0]\n",
    "X1[:5]\n",
    "# Om plaatje te krijgen\n",
    "# Hier is de ideal decision boundary linear en wordt met de hand berekend\n",
    "# Volgens mij hebben wij in een lab opdracht gewerkt aan functies die niet-lineaire boundaries plotten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model trainen op alle data\n",
    "# Alleen voor visualisatie en ideal decision boundary, alleen voor ons (in de rapportage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply decision function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ideal decision boundary, \n",
    "# dit is in het voorbeeld alleen om te laten zien dat de decision boundary dichterbij ideal komt met meer iteraties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deze stappen moet de designer wel allemaal doen (behalve welke afbeeldingen in een folder zetten, dat is voor de visualisatie):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier moet ik nog naar kijken: het is belangrijk om indexes te resetten, omdat dit voorbeeld de indexes als  \n",
    "# identifier gebruikt om te bepalen of een unknown sample bij de training data is gevoegd in een iteratie\n",
    "X1 = X1.reset_index(drop=True)\n",
    "y1 = y1.reset_index(drop=True)\n",
    "y1 -= 1\n",
    "print(y1.unique())\n",
    "X1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split pool - test (80-20)\n",
    "X_pool, X_test, y_pool, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds most ambiguous unlabelled point \n",
    "def find_most_ambiguous(clf, unknown_indexes):\n",
    "    \n",
    "    ind = np.argmin(np.abs( \n",
    "        list(clf0.decision_function(X_pool.iloc[unknown_indexes]) )\n",
    "        ))\n",
    "    return unknown_indexes[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots the decision boundary, and training and unknown 'pool' data points\n",
    "def plot_svm(clf, train_indexes, unknown_indexes, new_index = False, title = False, name = False):\n",
    "    X_train = X_pool.iloc[train_indexes]\n",
    "    y_train = y_pool.iloc[train_indexes]\n",
    "\n",
    "    X_unk = X_pool.iloc[unknown_indexes]\n",
    "\n",
    "    if new_index:\n",
    "        X_new = X_pool.iloc[new_index]\n",
    "\n",
    "    a, b, c = clf.coef_[0, 0], clf.coef_[0, 1], clf.intercept_\n",
    "    # Straight Line Formula\n",
    "    # a*x + b*y + c = 0\n",
    "    # y = -(a*x + c)/b\n",
    "\n",
    "    lx = [xmin + stepx * i for i in range(100)]\n",
    "    ly = [-(a*lx[i] + c)/b for i in range(100)]\n",
    "\n",
    "    fig = plt.figure(figsize=(9,6))\n",
    "\n",
    "    # plt.scatter(x[k1][setosa], x[k2][setosa], c='r')\n",
    "    plt.scatter(X_unk[k1], X_unk[k2], c='k', marker = '.')\n",
    "    plt.scatter(X_train[k1][y_train==0], X_train[k2][y_train==0], c='r', marker = 'o')\n",
    "    plt.scatter(X_train[k1][y_train==1], X_train[k2][y_train==1], c='c', marker = 'o')\n",
    "    \n",
    "\n",
    "    plt.plot(lx, ly, c='m')\n",
    "    plt.plot(lx0, ly0, '--', c='g')\n",
    "\n",
    "    if new_index:\n",
    "        plt.scatter(X_new[k1], X_new[k2], c='y', marker=\"*\", s=125)\n",
    "        plt.scatter(X_new[k1], X_new[k2], c='y', marker=\"*\", s=125)\n",
    "        plt.scatter(X_new[k1], X_new[k2], c='y', marker=\"*\", s=125)\n",
    "        plt.scatter(X_new[k1], X_new[k2], c='y', marker=\"*\", s=125)\n",
    "        plt.scatter(X_new[k1], X_new[k2], c='y', marker=\"*\", s=125)\n",
    "\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    \n",
    "    plt.xlabel(k1)\n",
    "    plt.ylabel(k2)\n",
    "\n",
    "    if name:\n",
    "        fig.set_size_inches((9,6))\n",
    "        plt.savefig(name, dpi=100)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train met 10/80 data points uit de pool. Dit is de eerste iteration (0)\n",
    "train_indexes = list(range(10))\n",
    "unknown_indexes = list(range(10, 80))\n",
    "X_train = X_pool.iloc[train_indexes]\n",
    "y_train = y_pool.iloc[train_indexes]\n",
    "# Wij moeten dus eerst een model vinden met de juiste tuning o.b.v. onze eigen volledig gelabelde data\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Vanaf hier gaat het over visualisatie\n",
    "\n",
    "# folder = \"rs1it5/\"\n",
    "folder = \"rs2it20/\"\n",
    "# folder = \"rs1it20/\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "filenames = [\"ActiveLearningTitleSlide2.jpg\"] * 2\n",
    "\n",
    "title = \"Beginning\"\n",
    "# name = folder + (\"rs1it5_0a.jpg\")\n",
    "name = folder + (\"rs2it20_0a.jpg\")\n",
    "plot_svm(clf, train_indexes, unknown_indexes, False, title, name)\n",
    "\n",
    "filenames.append(name)\n",
    "\n",
    "# Dit is wel belangrijk\n",
    "\n",
    "n = find_most_ambiguous(clf, unknown_indexes)\n",
    "unknown_indexes.remove(n)\n",
    "\n",
    "# Dit waarschijnlijk niet (voor de designer)\n",
    "\n",
    "title = \"Iteration 0\"\n",
    "name = folder + (\"rs1it5_0b.jpg\")\n",
    "# name = folder + (\"rs2it20_0b.jpg\")\n",
    "filenames.append(name)\n",
    "plot_svm(clf, train_indexes, unknown_indexes, n, title, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In elke iteratie wordt bepaald welk unknown sample het meest ambiguous is\n",
    "# (vraag de designer dus alleen om 10 punten te labellen, en laat elke iteratie 1 nieuw punt zien om te labellen)\n",
    "num = 5\n",
    "# num = 20\n",
    "t = []\n",
    "for i in range(num):\n",
    "    \n",
    "    train_indexes.append(n)\n",
    "    X_train = X_pool.iloc[train_indexes]\n",
    "    y_train = y_pool.iloc[train_indexes]\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    title, name = \"Iteration \"+str(i+1), folder + (\"rs1it5_%d.jpg\" % (i+1))\n",
    "    # title, name = \"Iteration \"+str(i+1), folder + (\"rs2it20_%d.jpg\" % (i+1))\n",
    "\n",
    "    n = find_most_ambiguous(clf, unknown_indexes)\n",
    "    unknown_indexes.remove(n)\n",
    "    plot_svm(clf, train_indexes, unknown_indexes, n, title, name)\n",
    "    filenames.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In het voorbeeld wordt een gif gemaakt die per iteratie laat zien hoeveel dichter je bij de ideal boundary komt, \n",
    "# kunnen wij ook doen maar dan moeten we wel echt PCA gebruiken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training samples opslaan op om voor tuning te gebruiken, als we dat willen \n",
    "# (we kunnen ook o.b.v. onze data een getuned model aan de designer geven) en hier eindigen met validatie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for overfitting with the 20% test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novelty detection en training integreren: active learning als iteratief proces (ga terug naar stap ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is het mogelijk om niet helemaal opnieuw te laten beginnen? Denk het wel: gebruik in iteratie 0 de intermediate gelabelde punten \n",
    "Opties: discard point, add an activity and retrain, label point (confirms expected activities while improving model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intervals labellen (zodat niet 10/15000 maar 4000/15000)... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nieuwe clusters: ver van decision boundary maar niet correct... (manier om most ambiguous met verste afstand van centroids te bepalen) (dus gaat om keuze svm (decision boundary) of knn (euclidean distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentatie:\n",
    "Input nodig = file met preprocessed data en deels getuned model\n",
    "Output = getraind model en set met training data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
