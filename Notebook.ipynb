{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Machine learning for IDE students application!\n",
    "\n",
    "This is a JupyterNotebook created for IDE students to get introduced to using machine learning for prototype improvement. It might seem like a lot if you don't have any coding experience, but just follow the steps, read the instructions and it should be a breeze! \n",
    "\n",
    "## Try the program\n",
    "\n",
    "We have filled out the program in such a way that everything is set up with an example dataset. Feel free to go through te application one time, before changing in to your own data / preferences. This way you can get a feeling of hoe the product works and what is needed for a good running program. \n",
    "\n",
    "\n",
    "## Setting up\n",
    "\n",
    "This application will take you through the preprocessing, labeling and classification steps of the machine learning process. Make sure you've read through the [User Guide](https://docs.google.com/document/d/1J9c5sHokh8Rj-4lO4yKX1Tv7LwY2_r-mfQ9YKviiXZk/edit?usp=sharing) before you continue.\n",
    "\n",
    "To be able to access the code we need to import packages. The second set of packages are written by us and contain the main functions of the program. The actual Python code is to be found in different files, so you have a nice interface without a bunch of code. \n",
    "\n",
    "**Make sure you run the two cells below!** To run your first cell, just click inside the cell and press play. You can consult [this tutorial](https://www.dataquest.io/blog/jupyter-notebook-tutorial/) if you experience difficulty using Anaconda.\n",
    "ATTENTION: This is a large operation, keep that in mind, this might take a few minutes. It is very important to run the code completely, so only continue after the * before the cell has disappeared"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are standard pythion packages that most programs need to run properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install numpy==1.21.4\n",
    "!pip3 install pandas==1.5.2\n",
    "!pip3 install matplotlib==3.6.3\n",
    "!pip3 install scikit-learn==1.2.0\n",
    "!pip3 install plotly==5.12.0\n",
    "!pip3 install IPython==8.8.0\n",
    "!pip3 install kaleido==0.2.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are our own packages, we created these for you so that you don't have to see all the code, but only the things you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AI_for_Designers.data_processing import Preprocessing, empty_files\n",
    "from AI_for_Designers.active_learning import ActiveLearning\n",
    "from AI_for_Designers.novelty_detection import NoveltyDetection\n",
    "from AI_for_Designers.data_stats import Stats\n",
    "from AI_for_Designers.Notebook import check_product_name, amount_of_samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, the name of the Product you are analysing can be changed. It helps to come up with a descriptive name like the name of the prototype. ATTENTION: the name should only contain letters, numbers, underscores and dashes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name is valid!\n"
     ]
    }
   ],
   "source": [
    "Product = 'Mok'\n",
    "check_product_name(Product)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "During preprocessing, the raw data gets divided into frames. Frames are data points that are encapsulated in a frame. This makes for more certain predictions and a faster model because it knows more about a frame and there are fewer datapoints.\n",
    "\n",
    "There are **4 variables** that are important for you to edit:\n",
    "\n",
    " - Frame_size: set larger for slow movements, smaller for very quick movements. A frame size of about the length of one action is advised. Default = 2 sec\n",
    " - Frame_offset: increase if you set a bigger frame size. A frame offset of around 10-20% of the frame size is advised. A lower frame offset might result in a more accurate model but will result in more work for you. Default = 0.2 sec\n",
    " - start_offset: set it to the time it takes in seconds between starting the recording and starting with the actual Product usage.\n",
    " - stop_offset: the same as the start-chop, but for the end of a recording\n",
    "\n",
    "Enter the values below, and run the cell to start the preprocessing. The frame size and the frame offset can be changed in the cell below, while the start-chop and the end-chap need to be changed in all the lines that start with 'pre.windowing'. ATTENTION: the frame size and the frame offset, need to be the same for all the different files, while the start-chop and the end-chop may differ.\n",
    "\n",
    "After you've preprocessed your data, the application will have extracted features like standard deviation and most present frequency. These features will be used to analyze the characteristics of a data point and classify it to an Product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_size = 0.8\n",
    "frame_offset = 0.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below is where you enter all the data and the variables. \n",
    "\n",
    "First it makes empty files for the data that is generated in the preprocessing. This is just for us to save the features and data, there is no need for you to see what this is, although you can take a look at them once the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of sensors: 6, amount of features per sensor: 8\n"
     ]
    }
   ],
   "source": [
    "empty_files([f'Preprocessed-data/{Product}/features_{Product}.txt',\n",
    "             f'Preprocessed-data/{Product}/features_{Product}_scaled.csv',\n",
    "             f'Preprocessed-data/{Product}/processed_data_files.txt'])\n",
    "\n",
    "pre = Preprocessing(Product)\n",
    "# pre.windowing([r\"Data/data-lopen/Walking_part_1.csv\", r\"Data/data-lopen/Walking_part_1_gyro.csv\"], r\"Data/data-lopen/Walking_part_1.mp4\",\n",
    "#               start_offset=2.5, stop_offset=5, size=1, offset=0.2, video_offset=2.5, epsilon=0.01, do_plot=False, do_scale=False)\n",
    "# pre.windowing([r\"Data/data-lopen/Walking_part_2.csv\", r\"Data/data-lopen/Walking_part_2_gyro.csv\"], r\"Data/data-lopen/Walking_part_2.mp4\",\n",
    "#               start_offset=2.5, stop_offset=5, size=1, offset=0.2, video_offset=2.5, epsilon=0.01, do_plot=False, do_scale=True)\n",
    "# pre.windowing([fr'Data\\data-cycling\\ACCL\\Timo_fietsen_GH010031-ACCL.csv', fr'Data\\data-cycling\\GYRO\\Timo_fietsen_GH010031-GYRO.csv'], 'Data\\data-cycling\\Fiets_filmpjes\\GL010031_LRV_compressed.mp4',\n",
    "#               start_offset=0, stop_offset=0, size=5, offset=0.5, epsilon=0.01, do_plot=False, do_scale=False)\n",
    "# pre.windowing([fr'Data\\data-cycling\\ACCL\\Timo_fietsen_GH010032-ACCL.csv', fr'Data\\data-cycling\\GYRO\\Timo_fietsen_GH010032-GYRO.csv'], 'Data\\data-cycling\\Fiets_filmpjes\\GL010032_LRV.mp4',\n",
    "#               start_offset=0, stop_offset=0, size=5, offset=0.5, epsilon=0.01, do_plot=False, do_scale=False)\n",
    "# pre.windowing([fr'Data\\data-cycling\\ACCL\\Timo_fietsen_GH010033-ACCL.csv', fr'Data\\data-cycling\\GYRO\\Timo_fietsen_GH010033-GYRO.csv'], 'Data\\data-cycling\\Fiets_filmpjes\\GL010033_LRV.mp4',\n",
    "#               start_offset=0, stop_offset=0, size=5, offset=0.5, epsilon=0.01, do_plot=False, do_scale=False)\n",
    "# pre.windowing([fr'Data\\data-cycling\\ACCL\\Timo_fietsen_GH010034-ACCL.csv', fr'Data\\data-cycling\\GYRO\\Timo_fietsen_GH010034-GYRO.csv'], 'Data\\data-cycling\\Fiets_filmpjes\\GL010034_LRV_compressed.mp4',\n",
    "#               start_offset=0, stop_offset=0, size=5, offset=0.5, epsilon=0.01, do_plot=False, do_scale=True)\n",
    "pre.windowing(input_file=[r'Data/data-mok/Gijs_Mok_GH010035-ACCL.csv', r'Data/data-mok/Gijs_Mok_GH010035-GYRO.csv'],\n",
    "              video_file='Data/data-mok/GL010035_LRV.mp4',\n",
    "              start_offset=0, \n",
    "              stop_offset=0, \n",
    "              size=frame_size,\n",
    "              offset=frame_offset)\n",
    "\n",
    "pre.SuperStandardScaler(fr'Preprocessed-data\\{Product}\\features_{Product}_scaled.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling and training\n",
    "\n",
    "If you've set up your preprocessing correctly this step should be quite easy. The application will show you part of your recording, and you will be asked to label it according to the action performed on screen. You can add a new label if the Product you see is not one of the options you expected. \n",
    "\n",
    "First, enter the activities that you think will be in the video. Don't worry about doing this extensively, you can always add more later.\n",
    "\n",
    "An example:\n",
    "\n",
    "    labels = ['walking', 'running', 'stairs_up', 'stairs_down']\n",
    "\n",
    "Enter your labels inside the code block below. **Only change the text inside the brackets, remember to put the values in quotation marks and seperate them by commas**.\n",
    "\n",
    "Next up is training the model. After entering your labels, run the cell and you will be shown a GIF and asked to label the Product you see. Take your time to label the data correctly, as the results fully rely on accurate labels. You get the option to delete a data point if you are not completely sure about the label (e.g. the sample contains two different actions) or if it's a faulty sample. \n",
    "\n",
    "The value of 'active_learning_iterations', is the amount of samples you will label. The more samples you label, the more accurate the model might become, but the more time it will consume. Labeling round 10-20% of the total amount of samples or at least 100 samples is advised. The cell below can be used to find the amount of available samples.\n",
    "\n",
    "After labeling 16 samples, a list (recognizable by its square bracets []) apears under the video with the probability that this frame is the corresponding label, so the first value in the list corresponds with the first option under the video.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1890\n"
     ]
    }
   ],
   "source": [
    "print(amount_of_samples(f'Preprocessed-data/{Product}/processed_data_files.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['stil', 'oppakken', 'neerzetten', 'drinken', 'lopen']\n",
    "active_learning_iterations = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130.89999999999685 0.8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <head>\n",
       "                <script type=\"text/javascript\">\n",
       "                    function init_0(){\n",
       "                        let timestamp = 130.89999999999685;\n",
       "                        let window_size = 0.8;\n",
       "                        let video = document.getElementById(\"0\");\n",
       "                        video.currentTime = timestamp;\n",
       "                        play_0();\n",
       "                    }\n",
       "\n",
       "                    function play_0(){\n",
       "                        let timestamp = 130.89999999999685;\n",
       "                        let window_size = 0.8;\n",
       "                        let video = document.getElementById(\"0\");\n",
       "                        if (video.currentTime < timestamp || video.currentTime >= timestamp + window_size){\n",
       "                            video.currentTime = timestamp;\n",
       "                        }\n",
       "                        video.play();\n",
       "                        setInterval(function(){\n",
       "                            if(video.currentTime >= timestamp + window_size){\n",
       "                                video.currentTime = timestamp;\n",
       "                            }\n",
       "                        },1);\n",
       "                        <!--video.playbackRate = 2-->\n",
       "                    }\n",
       "\n",
       "                    function pause_0(){\n",
       "                        let timestamp = 130.89999999999685;\n",
       "                        let window_size = 0.8;\n",
       "                        let video = document.getElementById(\"0\");\n",
       "                        video.pause();\n",
       "                    }\n",
       "                </script>\n",
       "            </head>\n",
       "            <body>\n",
       "                <div style=\"display:flex\">\n",
       "                    <div style=\"flex:1\">\n",
       "                        <video id=\"0\" height=\"300px\" src=\"Data/data-mok/GL010035_LRV.mp4\" muted></video><br>\n",
       "                        <script type=\"text/javascript\">init_0()</script>\n",
       "                        <button onclick=\"play_0()\">Play</button>\n",
       "                        <button onclick=\"pause_0()\">Pause</button>\n",
       "                    </div>\n",
       "                    <div style=\"flex:1\">  \n",
       "                        <img id=\"image\" src=\"Plots/plot_to_label_0.png\" height=\"300px\"></img>\n",
       "                        <script type=\"text/javascript\">\n",
       "                        if (0 === -1) {\n",
       "                            document.getElementById(\"image\").src = \"\";\n",
       "                        }\n",
       "                        </script>\n",
       "                    </div>\n",
       "                </div>\n",
       "            </body>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the index or the name of one of the following labels. Enter 'n' to add a new label or 'x' to discard this sample:\n",
      "1. stil\n",
      "2. oppakken\n",
      "3. neerzetten\n",
      "4. drinken\n",
      "5. lopen\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m AL \u001B[39m=\u001B[39m ActiveLearning(\u001B[39mfr\u001B[39m\u001B[39m'\u001B[39m\u001B[39mPreprocessed-data/\u001B[39m\u001B[39m{\u001B[39;00mProduct\u001B[39m}\u001B[39;00m\u001B[39m/features_\u001B[39m\u001B[39m{\u001B[39;00mProduct\u001B[39m}\u001B[39;00m\u001B[39m_scaled.csv\u001B[39m\u001B[39m'\u001B[39m, Product, labels, frame_size)\n\u001B[1;32m----> 2\u001B[0m labels \u001B[39m=\u001B[39m AL\u001B[39m.\u001B[39;49mtraining(active_learning_iterations, random_points\u001B[39m=\u001B[39;49m\u001B[39m1\u001B[39;49m)\n\u001B[0;32m      3\u001B[0m AL\u001B[39m.\u001B[39mplotting()\n\u001B[0;32m      4\u001B[0m AL\u001B[39m.\u001B[39mwrite_to_file()\n",
      "File \u001B[1;32mc:\\Users\\timoz\\Documents\\TU Delft\\TI3150\\Capstone-AI-IoT\\AI_for_Designers\\active_learning.py:129\u001B[0m, in \u001B[0;36mActiveLearning.training\u001B[1;34m(self, maximum_iterations, random_points, cluster_points)\u001B[0m\n\u001B[0;32m    126\u001B[0m             os\u001B[39m.\u001B[39mremove(f)\n\u001B[0;32m    128\u001B[0m \u001B[39m# Set randomized starting points       \u001B[39;00m\n\u001B[1;32m--> 129\u001B[0m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mset_starting_points(random_points)\n\u001B[0;32m    131\u001B[0m \u001B[39m# Set the predicted and und predicted sets into new arrays, these will be used further on\u001B[39;00m\n\u001B[0;32m    132\u001B[0m \u001B[39m# print(self.X_pool.loc[self.X_pool['label'] != ''])\u001B[39;00m\n\u001B[0;32m    133\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mpreds \u001B[39m=\u001B[39m np\u001B[39m.\u001B[39marray(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39mX_pool\u001B[39m.\u001B[39mloc[\u001B[39mself\u001B[39m\u001B[39m.\u001B[39mX_pool[\u001B[39m'\u001B[39m\u001B[39mlabel\u001B[39m\u001B[39m'\u001B[39m] \u001B[39m!=\u001B[39m \u001B[39m'\u001B[39m\u001B[39m'\u001B[39m])\n",
      "File \u001B[1;32mc:\\Users\\timoz\\Documents\\TU Delft\\TI3150\\Capstone-AI-IoT\\AI_for_Designers\\active_learning.py:175\u001B[0m, in \u001B[0;36mActiveLearning.set_starting_points\u001B[1;34m(self, n_samples)\u001B[0m\n\u001B[0;32m    172\u001B[0m         \u001B[39mbreak\u001B[39;00m\n\u001B[0;32m    173\u001B[0m \u001B[39m# Give the timestamp to the identification module but for testing I have automated it\u001B[39;00m\n\u001B[0;32m    174\u001B[0m \u001B[39m# got_labeled = self.identify(self.datapd.iloc[random_id]['time'])\u001B[39;00m\n\u001B[1;32m--> 175\u001B[0m got_labeled \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49midentify(random_id)  \u001B[39m# for testing\u001B[39;00m\n\u001B[0;32m    176\u001B[0m \u001B[39mif\u001B[39;00m got_labeled \u001B[39m==\u001B[39m \u001B[39m'\u001B[39m\u001B[39mx\u001B[39m\u001B[39m'\u001B[39m:\n\u001B[0;32m    177\u001B[0m     \u001B[39mprint\u001B[39m(np\u001B[39m.\u001B[39mwhere(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39mdatapd\u001B[39m.\u001B[39miloc[:, \u001B[39m0\u001B[39m] \u001B[39m==\u001B[39m random_id))\n",
      "File \u001B[1;32mc:\\Users\\timoz\\Documents\\TU Delft\\TI3150\\Capstone-AI-IoT\\AI_for_Designers\\active_learning.py:382\u001B[0m, in \u001B[0;36mActiveLearning.identify\u001B[1;34m(self, id, les_probs, process)\u001B[0m\n\u001B[0;32m    379\u001B[0m \u001B[39m# print(id)\u001B[39;00m\n\u001B[0;32m    380\u001B[0m \u001B[39m# print(video_file)\u001B[39;00m\n\u001B[0;32m    381\u001B[0m \u001B[39mif\u001B[39;00m les_probs \u001B[39mis\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n\u001B[1;32m--> 382\u001B[0m     \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mvid\u001B[39m.\u001B[39;49mlabeling(video_file, timestamp, \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mwindow_size, \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mhtml_id, process\u001B[39m=\u001B[39;49mprocess, video_offset\u001B[39m=\u001B[39;49mvideo_offset)\n\u001B[0;32m    383\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[0;32m    384\u001B[0m     \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mvid\u001B[39m.\u001B[39mlabeling(video_file, timestamp, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mwindow_size, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mhtml_id, les_probs, process\u001B[39m=\u001B[39mprocess, video_offset\u001B[39m=\u001B[39mvideo_offset)\n",
      "File \u001B[1;32mc:\\Users\\timoz\\Documents\\TU Delft\\TI3150\\Capstone-AI-IoT\\AI_for_Designers\\Videolabeler.py:47\u001B[0m, in \u001B[0;36mVideoLabeler.labeling\u001B[1;34m(self, video_file, timestamp, window_size, fig_id, probs, process, video_offset)\u001B[0m\n\u001B[0;32m     45\u001B[0m     \u001B[39mprint\u001B[39m(\u001B[39mf\u001B[39m\u001B[39m'\u001B[39m\u001B[39m{\u001B[39;00mi \u001B[39m+\u001B[39m \u001B[39m1\u001B[39m\u001B[39m}\u001B[39;00m\u001B[39m. \u001B[39m\u001B[39m{\u001B[39;00mlabel\u001B[39m}\u001B[39;00m\u001B[39m'\u001B[39m)\n\u001B[0;32m     46\u001B[0m \u001B[39m# Get the input from the user\u001B[39;00m\n\u001B[1;32m---> 47\u001B[0m new_label \u001B[39m=\u001B[39m \u001B[39minput\u001B[39;49m()\n\u001B[0;32m     49\u001B[0m \u001B[39mtry\u001B[39;00m:\n\u001B[0;32m     50\u001B[0m     \u001B[39m# Try casting the input to an integer if possible\u001B[39;00m\n\u001B[0;32m     51\u001B[0m     index \u001B[39m=\u001B[39m \u001B[39mint\u001B[39m(new_label)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py:1177\u001B[0m, in \u001B[0;36mKernel.raw_input\u001B[1;34m(self, prompt)\u001B[0m\n\u001B[0;32m   1173\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_allow_stdin:\n\u001B[0;32m   1174\u001B[0m     \u001B[39mraise\u001B[39;00m StdinNotImplementedError(\n\u001B[0;32m   1175\u001B[0m         \u001B[39m\"\u001B[39m\u001B[39mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[39m\"\u001B[39m\n\u001B[0;32m   1176\u001B[0m     )\n\u001B[1;32m-> 1177\u001B[0m \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_input_request(\n\u001B[0;32m   1178\u001B[0m     \u001B[39mstr\u001B[39;49m(prompt),\n\u001B[0;32m   1179\u001B[0m     \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_parent_ident[\u001B[39m\"\u001B[39;49m\u001B[39mshell\u001B[39;49m\u001B[39m\"\u001B[39;49m],\n\u001B[0;32m   1180\u001B[0m     \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mget_parent(\u001B[39m\"\u001B[39;49m\u001B[39mshell\u001B[39;49m\u001B[39m\"\u001B[39;49m),\n\u001B[0;32m   1181\u001B[0m     password\u001B[39m=\u001B[39;49m\u001B[39mFalse\u001B[39;49;00m,\n\u001B[0;32m   1182\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py:1219\u001B[0m, in \u001B[0;36mKernel._input_request\u001B[1;34m(self, prompt, ident, parent, password)\u001B[0m\n\u001B[0;32m   1216\u001B[0m             \u001B[39mbreak\u001B[39;00m\n\u001B[0;32m   1217\u001B[0m \u001B[39mexcept\u001B[39;00m \u001B[39mKeyboardInterrupt\u001B[39;00m:\n\u001B[0;32m   1218\u001B[0m     \u001B[39m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[1;32m-> 1219\u001B[0m     \u001B[39mraise\u001B[39;00m \u001B[39mKeyboardInterrupt\u001B[39;00m(\u001B[39m\"\u001B[39m\u001B[39mInterrupted by user\u001B[39m\u001B[39m\"\u001B[39m) \u001B[39mfrom\u001B[39;00m \u001B[39mNone\u001B[39m\n\u001B[0;32m   1220\u001B[0m \u001B[39mexcept\u001B[39;00m \u001B[39mException\u001B[39;00m:\n\u001B[0;32m   1221\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mlog\u001B[39m.\u001B[39mwarning(\u001B[39m\"\u001B[39m\u001B[39mInvalid Message:\u001B[39m\u001B[39m\"\u001B[39m, exc_info\u001B[39m=\u001B[39m\u001B[39mTrue\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "AL = ActiveLearning(fr'Preprocessed-data/{Product}/features_{Product}_scaled.csv', Product, labels, frame_size)\n",
    "labels = AL.training(active_learning_iterations, random_points=1)\n",
    "AL.plotting()\n",
    "AL.write_to_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get an idea of how accurate the model is, it is advised to label some more data. These frames are not used in training the model, but the model is used to predict the action that is happening in this frame. By telling the model which action actually is happening in the frame, the accuracy can be measured, by calculating the error rate (dividing the wrong labled frames by the total amount of frames). It is advised to label at least 20 frames, but preferably more (about 50). The more frames are labled, the better the indication of the accuracy is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL.testing(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <head>\n",
       "                    <script type=\"text/javascript\">\n",
       "                    let id = 0;\n",
       "                    const time_video = [[0.0, 'Data/data-mok/GL010035_LRV.mp4'], [0.1, 'Data/data-mok/GL010035_LRV.mp4'], [0.3, 'Data/data-mok/GL010035_LRV.mp4'], [1.4, 'Data/data-mok/GL010035_LRV.mp4'], [3.1000000000000014, 'Data/data-mok/GL010035_LRV.mp4'], [3.3000000000000016, 'Data/data-mok/GL010035_LRV.mp4'], [3.900000000000002, 'Data/data-mok/GL010035_LRV.mp4'], [5.1999999999999975, 'Data/data-mok/GL010035_LRV.mp4'], [5.299999999999997, 'Data/data-mok/GL010035_LRV.mp4'], [5.399999999999997, 'Data/data-mok/GL010035_LRV.mp4'], [5.4999999999999964, 'Data/data-mok/GL010035_LRV.mp4'], [5.599999999999996, 'Data/data-mok/GL010035_LRV.mp4'], [5.999999999999995, 'Data/data-mok/GL010035_LRV.mp4'], [6.099999999999994, 'Data/data-mok/GL010035_LRV.mp4'], [6.199999999999994, 'Data/data-mok/GL010035_LRV.mp4'], [6.399999999999993, 'Data/data-mok/GL010035_LRV.mp4'], [9.199999999999983, 'Data/data-mok/GL010035_LRV.mp4'], [9.99999999999998, 'Data/data-mok/GL010035_LRV.mp4'], [10.19999999999998, 'Data/data-mok/GL010035_LRV.mp4'], [10.29999999999998, 'Data/data-mok/GL010035_LRV.mp4'], [10.39999999999998, 'Data/data-mok/GL010035_LRV.mp4'], [10.49999999999998, 'Data/data-mok/GL010035_LRV.mp4'], [10.699999999999978, 'Data/data-mok/GL010035_LRV.mp4'], [17.099999999999973, 'Data/data-mok/GL010035_LRV.mp4'], [17.399999999999977, 'Data/data-mok/GL010035_LRV.mp4'], [17.49999999999998, 'Data/data-mok/GL010035_LRV.mp4'], [19.1, 'Data/data-mok/GL010035_LRV.mp4'], [19.300000000000004, 'Data/data-mok/GL010035_LRV.mp4'], [19.500000000000007, 'Data/data-mok/GL010035_LRV.mp4'], [24.100000000000072, 'Data/data-mok/GL010035_LRV.mp4'], [24.200000000000077, 'Data/data-mok/GL010035_LRV.mp4'], [24.300000000000075, 'Data/data-mok/GL010035_LRV.mp4'], [24.50000000000008, 'Data/data-mok/GL010035_LRV.mp4'], [24.900000000000084, 'Data/data-mok/GL010035_LRV.mp4'], [25.000000000000085, 'Data/data-mok/GL010035_LRV.mp4'], [25.200000000000088, 'Data/data-mok/GL010035_LRV.mp4'], [26.70000000000011, 'Data/data-mok/GL010035_LRV.mp4'], [26.900000000000112, 'Data/data-mok/GL010035_LRV.mp4'], [27.100000000000115, 'Data/data-mok/GL010035_LRV.mp4'], [27.700000000000124, 'Data/data-mok/GL010035_LRV.mp4'], [28.600000000000136, 'Data/data-mok/GL010035_LRV.mp4'], [28.700000000000134, 'Data/data-mok/GL010035_LRV.mp4'], [28.80000000000014, 'Data/data-mok/GL010035_LRV.mp4'], [29.000000000000146, 'Data/data-mok/GL010035_LRV.mp4'], [31.900000000000183, 'Data/data-mok/GL010035_LRV.mp4'], [32.100000000000186, 'Data/data-mok/GL010035_LRV.mp4'], [35.30000000000023, 'Data/data-mok/GL010035_LRV.mp4'], [35.500000000000234, 'Data/data-mok/GL010035_LRV.mp4'], [35.60000000000024, 'Data/data-mok/GL010035_LRV.mp4'], [35.70000000000024, 'Data/data-mok/GL010035_LRV.mp4'], [35.90000000000024, 'Data/data-mok/GL010035_LRV.mp4'], [36.00000000000024, 'Data/data-mok/GL010035_LRV.mp4'], [36.20000000000024, 'Data/data-mok/GL010035_LRV.mp4'], [36.300000000000246, 'Data/data-mok/GL010035_LRV.mp4'], [36.40000000000025, 'Data/data-mok/GL010035_LRV.mp4'], [36.900000000000254, 'Data/data-mok/GL010035_LRV.mp4'], [37.000000000000256, 'Data/data-mok/GL010035_LRV.mp4'], [37.10000000000026, 'Data/data-mok/GL010035_LRV.mp4'], [37.20000000000026, 'Data/data-mok/GL010035_LRV.mp4'], [37.50000000000026, 'Data/data-mok/GL010035_LRV.mp4'], [37.60000000000026, 'Data/data-mok/GL010035_LRV.mp4'], [37.80000000000027, 'Data/data-mok/GL010035_LRV.mp4'], [37.90000000000027, 'Data/data-mok/GL010035_LRV.mp4'], [38.00000000000027, 'Data/data-mok/GL010035_LRV.mp4'], [40.70000000000031, 'Data/data-mok/GL010035_LRV.mp4'], [40.80000000000031, 'Data/data-mok/GL010035_LRV.mp4'], [41.00000000000031, 'Data/data-mok/GL010035_LRV.mp4'], [41.80000000000032, 'Data/data-mok/GL010035_LRV.mp4'], [50.300000000000445, 'Data/data-mok/GL010035_LRV.mp4'], [52.00000000000047, 'Data/data-mok/GL010035_LRV.mp4'], [54.0000000000005, 'Data/data-mok/GL010035_LRV.mp4'], [55.80000000000052, 'Data/data-mok/GL010035_LRV.mp4'], [59.10000000000057, 'Data/data-mok/GL010035_LRV.mp4'], [59.20000000000057, 'Data/data-mok/GL010035_LRV.mp4'], [59.400000000000574, 'Data/data-mok/GL010035_LRV.mp4'], [59.70000000000058, 'Data/data-mok/GL010035_LRV.mp4'], [59.90000000000058, 'Data/data-mok/GL010035_LRV.mp4'], [60.00000000000058, 'Data/data-mok/GL010035_LRV.mp4'], [60.10000000000058, 'Data/data-mok/GL010035_LRV.mp4'], [62.70000000000062, 'Data/data-mok/GL010035_LRV.mp4'], [63.00000000000063, 'Data/data-mok/GL010035_LRV.mp4'], [64.00000000000064, 'Data/data-mok/GL010035_LRV.mp4'], [68.00000000000041, 'Data/data-mok/GL010035_LRV.mp4'], [70.50000000000027, 'Data/data-mok/GL010035_LRV.mp4'], [70.70000000000026, 'Data/data-mok/GL010035_LRV.mp4'], [72.00000000000018, 'Data/data-mok/GL010035_LRV.mp4'], [75.99999999999996, 'Data/data-mok/GL010035_LRV.mp4'], [76.09999999999995, 'Data/data-mok/GL010035_LRV.mp4'], [77.29999999999988, 'Data/data-mok/GL010035_LRV.mp4'], [77.89999999999985, 'Data/data-mok/GL010035_LRV.mp4'], [93.19999999999898, 'Data/data-mok/GL010035_LRV.mp4'], [93.59999999999896, 'Data/data-mok/GL010035_LRV.mp4'], [93.69999999999897, 'Data/data-mok/GL010035_LRV.mp4'], [93.79999999999896, 'Data/data-mok/GL010035_LRV.mp4'], [93.99999999999892, 'Data/data-mok/GL010035_LRV.mp4'], [100.19999999999858, 'Data/data-mok/GL010035_LRV.mp4'], [101.49999999999852, 'Data/data-mok/GL010035_LRV.mp4'], [101.6999999999985, 'Data/data-mok/GL010035_LRV.mp4'], [103.5999999999984, 'Data/data-mok/GL010035_LRV.mp4'], [103.69999999999838, 'Data/data-mok/GL010035_LRV.mp4'], [104.29999999999836, 'Data/data-mok/GL010035_LRV.mp4'], [104.89999999999831, 'Data/data-mok/GL010035_LRV.mp4'], [108.19999999999813, 'Data/data-mok/GL010035_LRV.mp4'], [114.0999999999978, 'Data/data-mok/GL010035_LRV.mp4'], [114.39999999999776, 'Data/data-mok/GL010035_LRV.mp4'], [115.19999999999771, 'Data/data-mok/GL010035_LRV.mp4'], [115.39999999999772, 'Data/data-mok/GL010035_LRV.mp4'], [115.6999999999977, 'Data/data-mok/GL010035_LRV.mp4'], [115.7999999999977, 'Data/data-mok/GL010035_LRV.mp4'], [117.79999999999758, 'Data/data-mok/GL010035_LRV.mp4'], [118.59999999999754, 'Data/data-mok/GL010035_LRV.mp4'], [119.09999999999752, 'Data/data-mok/GL010035_LRV.mp4'], [122.09999999999734, 'Data/data-mok/GL010035_LRV.mp4'], [126.1999999999971, 'Data/data-mok/GL010035_LRV.mp4'], [126.39999999999708, 'Data/data-mok/GL010035_LRV.mp4'], [134.29999999999666, 'Data/data-mok/GL010035_LRV.mp4'], [135.69999999999658, 'Data/data-mok/GL010035_LRV.mp4'], [136.09999999999656, 'Data/data-mok/GL010035_LRV.mp4'], [137.79999999999646, 'Data/data-mok/GL010035_LRV.mp4'], [138.09999999999644, 'Data/data-mok/GL010035_LRV.mp4'], [142.1999999999962, 'Data/data-mok/GL010035_LRV.mp4'], [144.49999999999608, 'Data/data-mok/GL010035_LRV.mp4'], [144.79999999999606, 'Data/data-mok/GL010035_LRV.mp4'], [144.89999999999606, 'Data/data-mok/GL010035_LRV.mp4'], [145.09999999999604, 'Data/data-mok/GL010035_LRV.mp4'], [148.69999999999584, 'Data/data-mok/GL010035_LRV.mp4'], [148.99999999999582, 'Data/data-mok/GL010035_LRV.mp4'], [153.19999999999558, 'Data/data-mok/GL010035_LRV.mp4'], [153.29999999999558, 'Data/data-mok/GL010035_LRV.mp4'], [153.59999999999556, 'Data/data-mok/GL010035_LRV.mp4'], [153.99999999999554, 'Data/data-mok/GL010035_LRV.mp4'], [157.19999999999536, 'Data/data-mok/GL010035_LRV.mp4'], [158.99999999999525, 'Data/data-mok/GL010035_LRV.mp4'], [159.8999999999952, 'Data/data-mok/GL010035_LRV.mp4'], [160.29999999999518, 'Data/data-mok/GL010035_LRV.mp4'], [160.49999999999517, 'Data/data-mok/GL010035_LRV.mp4'], [160.59999999999516, 'Data/data-mok/GL010035_LRV.mp4'], [165.2999999999949, 'Data/data-mok/GL010035_LRV.mp4'], [168.19999999999473, 'Data/data-mok/GL010035_LRV.mp4'], [170.99999999999457, 'Data/data-mok/GL010035_LRV.mp4'], [171.09999999999457, 'Data/data-mok/GL010035_LRV.mp4'], [175.29999999999433, 'Data/data-mok/GL010035_LRV.mp4'], [175.39999999999432, 'Data/data-mok/GL010035_LRV.mp4'], [175.49999999999432, 'Data/data-mok/GL010035_LRV.mp4'], [175.5999999999943, 'Data/data-mok/GL010035_LRV.mp4'], [179.1999999999941, 'Data/data-mok/GL010035_LRV.mp4'], [179.2999999999941, 'Data/data-mok/GL010035_LRV.mp4'], [180.29999999999404, 'Data/data-mok/GL010035_LRV.mp4'], [181.799999999994, 'Data/data-mok/GL010035_LRV.mp4'], [183.39999999999387, 'Data/data-mok/GL010035_LRV.mp4'], [188.99999999999355, 'Data/data-mok/GL010035_LRV.mp4']];\n",
       "                    let time = time_video[0][0];\n",
       "                    const ws = 0.8;\n",
       "\n",
       "                    function init_nov() {\n",
       "                        let video = document.getElementById(\"nov\");\n",
       "                        video.currentTime = time;\n",
       "                        play_nov();\n",
       "                    }\n",
       "\n",
       "                    function play_nov() {\n",
       "                        let video = document.getElementById(\"nov\");\n",
       "                        if (video.currentTime < time || video.currentTime >= time + ws) {\n",
       "                            video.currentTime = time;\n",
       "                        }\n",
       "                        video.play();\n",
       "                        setInterval(function () {\n",
       "                            if (video.currentTime >= time + ws) {\n",
       "                                video.currentTime = time;\n",
       "                            }\n",
       "                        }, 1);\n",
       "                    }\n",
       "\n",
       "                    function pause_nov() {\n",
       "                        let video = document.getElementById(\"nov\");\n",
       "                        video.pause();\n",
       "                    }\n",
       "\n",
       "                    function prev_nov() {\n",
       "                    if (id >= 0) {\n",
       "                            id = id - 1;\n",
       "                            time = time_video[id][0];\n",
       "                            let video = document.getElementById(\"nov\");\n",
       "                            video.setAttribute('src', time_video[id][1]);\n",
       "                            document.getElementById(\"content\").innerHTML = 'Novelty ' + (id + 1) + ' out of 151 at ' + time + 's in ' + time_video[id][1];\n",
       "                            // document.getElementById(\"content2\").innerHTML = time_video[id][1];\n",
       "                            // document.getElementById(\"content3\").innerHTML = time;\n",
       "                            play_nov();\n",
       "                        }\n",
       "                    }\n",
       "\n",
       "                    function next_nov() {\n",
       "                        if (id < 151 - 1) {\n",
       "                            id = id + 1;\n",
       "                            time = time_video[id][0];\n",
       "                            let video = document.getElementById(\"nov\");\n",
       "                            video.setAttribute('src', time_video[id][1]);\n",
       "                            document.getElementById(\"content\").innerHTML = 'Novelty ' + (id + 1) + ' out of 151 at ' + time + 's in ' + time_video[id][1];\n",
       "                            // document.getElementById(\"content2\").innerHTML = time_video[id][1];\n",
       "                            // document.getElementById(\"content3\").innerHTML = time;\n",
       "                            play_nov();\n",
       "                        }\n",
       "                    }\n",
       "\n",
       "                    </script>\n",
       "                    <title></title>\n",
       "                </head>\n",
       "                <body>\n",
       "                    <video id=\"nov\" width=\"500px\" src=\"Data/data-mok/GL010035_LRV.mp4\" muted></video>\n",
       "                    <br>\n",
       "                    <script type=\"text/javascript\">init_nov()</script>\n",
       "                    <button onClick=\"play_nov()\">Play</button>\n",
       "                    <button onClick=\"pause_nov()\">Pause</button>\n",
       "                    <button onClick=\"prev_nov()\">Previous novelty</button>\n",
       "                    <button onClick=\"next_nov()\">Next novelty</button>\n",
       "                    <div id=\"content\">Novelty 1 out of 151 at 0.0s in Data/data-mok/GL010035_LRV.mp4</div>\n",
       "                    <!--<div id=\"content2\"></div>\n",
       "                    <div id=\"content3\"></div>-->\n",
       "                </body>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ND = NoveltyDetection(fr'Preprocessed-data/{Product}/features_{Product}_scaled_AL_predictionss.csv', fr'Preprocessed-data/{Product}/processed_data_files.txt')\n",
    "novelties = ND.detect(0.1)\n",
    "ND.play_novelties(novelties, frame_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = Stats(fr'Preprocessed-data/{Product}/features_{Product}_scaled_AL_predictionss.csv', labels)\n",
    "stats.print_percentages()\n",
    "stats.show_ghan_chart(frame_offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Data\n",
    "\n",
    "In the section beneath we will quickly run through some of the same steps as above, but now we can feed the model that we created with new, unseen data. The model created in the steps above will be used to predict the actions happening in this unseen data. This can be helpful for testing the robustness of your model when data was gathered by different people.\n",
    "\n",
    "Now you can feed the trained model more data, for example about real-life use of your product, by changing the 'pre_new.windowing' function!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "empty_files([f'Preprocessed-data/{Product}_new/features_{Product}_new.txt',\n",
    "             f'Preprocessed-data/{Product}_new/features_{Product}_new_scaled.csv',\n",
    "             f'Preprocessed-data/{Product}_new/processed_data_files.txt'])\n",
    "\n",
    "# Load the model that you made using pickle\n",
    "model = pickle.load(open(fr'Models/model_{Product}_{active_learning_iterations}.pickle', 'rb'))\n",
    "\n",
    "# Preprocess the new data\n",
    "pre_new = Preprocessing(f'{Product}_new')\n",
    "pre_new.windowing([r'GoPro\\Gijs_Mok\\Gijs_Mok_GH010035-ACCL.csv', r'GoPro\\Gijs_Mok\\Gijs_Mok_GH010035-GYRO.csv'], 'GoPro\\Gijs_Mok\\GL010035_LRV.mp4',\n",
    "              start_offset=0, stop_offset=0, size=frame_size, offset=frame_offset, epsilon=0.01, do_plot=False, do_scale=True)\n",
    "\n",
    "# Predict the label of all samples based on the \n",
    "new_dataset = pd.read_csv(fr'Preprocessed-data/{Product}_new/features_{Product}_new_scaled.csv', delimiter=',')\n",
    "predictions = model.predict(np.array(new_dataset.iloc[:, 3:]))\n",
    "\n",
    "# Replace the labels and write them to a new AL prediction file\n",
    "new_dataset['label'] = predictions\n",
    "new_dataset.to_csv(fr'Preprocessed-data/{Product}_new/features_{Product}_new_scaled_AL_predictionss.csv', index=False)\n",
    "\n",
    "# Use the new file to retrieve the predicted timeline\n",
    "stats = Stats(fr'Preprocessed-data/{Product}_new/features_{Product}_new_scaled_AL_predictionss.csv', labels)\n",
    "stats.print_percentages()\n",
    "stats.show_ghan_chart(frame_offset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "529ecdcae69add5700b168af870c2c245dc5754f1a82655f7b34366657b0a28f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
