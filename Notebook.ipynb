{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Machine learning for IDE students application!\n",
    "\n",
    "This is a JupyterNotebook created for IDE students to get introduced to using machine learning for prototype improvement. It might seem like a lot if you don't have any coding experience, but just follow the steps, read the instructions and it should be a breeze! \n",
    "\n",
    "## Try the program\n",
    "\n",
    "We have filled out the program in such a way that everything is set up with an example dataset. Feel free to go through te application one time, before changing in to your own data / preferences. This way you can get a feeling of hoe the product works and what is needed for a good running program. \n",
    "\n",
    "\n",
    "## Setting up\n",
    "\n",
    "This application will take you through the preprocessing, labeling and classification steps of the machine learning process. Make sure you've read through the [User Guide](https://docs.google.com/document/d/1J9c5sHokh8Rj-4lO4yKX1Tv7LwY2_r-mfQ9YKviiXZk/edit?usp=sharing) before you continue.\n",
    "\n",
    "\n",
    "### Kernel\n",
    "\n",
    "The kernel is like the engine of the application, this runs all the python code. Sometimes the kernel crashes, most of the times it is because of a bug. When the kernel has crashed, you need to restart it under the kernel tab in the notebook. When you restart the kernel you need to run most cells again depending on where you were in the process. Sometimes you do not need to do the prepocessing and labeling again, depending if you have already finished this. Alls cells that you have not ran before the kernel crashed, do not need to be rerun!.\n",
    "\n",
    "**Cells to run when the kernel crashes:** 2,3,4,7\n",
    "\n",
    "**Cells you do not have to rerun:** 1\n",
    "\n",
    "### Setting up the packages\n",
    "\n",
    "To be able to access the code we need to import packages. The second set of packages are written by us and contain the main functions of the program. The actual Python code is to be found in different files, so you have a nice interface without a bunch of code.\n",
    "\n",
    "**Make sure you run the two cells below!** To run your first cell, just click inside the cell and press play. You can consult [this tutorial](https://www.dataquest.io/blog/jupyter-notebook-tutorial/) if you experience difficulty using Anaconda.\n",
    "ATTENTION: This is a large operation, keep that in mind, this might take a few minutes. It is very important to run the code completely, so only continue after the * before the cell has disappeared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are standard python packages that most programs need to run properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "\n",
    "# installing all the online packages that are needed for the program.\n",
    "!pip3 install numpy==1.21.4\n",
    "!pip3 install pandas==1.5.2\n",
    "!pip3 install matplotlib==3.6.3\n",
    "!pip3 install scikit-learn==1.2.0\n",
    "!pip3 install plotly==5.12.0\n",
    "!pip3 install IPython==8.8.0\n",
    "!pip3 install kaleido==0.2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are our own packages, we created these for you so that you don't have to see all the code, but only the things you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "\n",
    "#Importing all the local packages that have been made for this application.\n",
    "from AI_for_Designers.data_processing import Preprocessing, empty_files\n",
    "from AI_for_Designers.active_learning import ActiveLearning\n",
    "from AI_for_Designers.novelty_detection import NoveltyDetection\n",
    "from AI_for_Designers.data_stats import Stats\n",
    "from AI_for_Designers.Notebook import check_product_name, amount_of_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, the name of the Product you are analysing can be changed. It helps to come up with a descriptive name like the name of the prototype. ATTENTION: the name should only contain letters, numbers, underscores and dashes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name is valid!\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "\n",
    "# Naming the product that is analysed eg. 'Vacuum_cleaner' 'chair' 'tablet'\n",
    "Product = 'Mok'\n",
    "check_product_name(Product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "Pre-processing is needed to create understandable information for the computer. Raw telemetry data like ours is hard to understand for the computer, therefore we conduct pre-processing. During preprocessing, the raw data gets divided into frames. Frames are data points that are encapsulated in a frame. This makes for more certain predictions and a faster model because it knows more about a frame and there are fewer datapoints.\n",
    "\n",
    "There are **4 variables** that are important for you to edit:\n",
    "\n",
    " - `frame_size`: set larger for slow movements, smaller for very quick movements. A frame size of about the length of one action is advised. Default = 2 sec\n",
    " - `frame_offset`: increase if you set a bigger frame size. A frame offset of around 10-20% of the frame size is advised. A lower frame offset might result in a more accurate model but will result in more work for you. Default = 0.2 sec\n",
    " - `start_offset`: set it to the time it takes in seconds between starting the recording and starting with the actual Product usage.\n",
    " - `stop_offset`: the same as the start_offset, but for the end of a recording\n",
    "\n",
    "Enter the values below, and run the cell to start the preprocessing. The frame size and the frame offset can be changed in the cell below, while the start_offset and the stop_offset need to be changed in all the lines that start with 'pre.windowing'. ATTENTION: the frame size and the frame offset, need to be the same for all the different files, while the start_offset and the stop_offset may differ.\n",
    "\n",
    "After you've preprocessed your data, the application will have extracted features like standard deviation and most present frequency. These features will be used to analyze the characteristics of a frame and classify it to the action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "\n",
    "# Setting the frame size and frame offset\n",
    "frame_size = 0.7\n",
    "frame_offset = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below is where you enter all the data and the variables. \n",
    "\n",
    "First it makes empty files for the data that is generated in the preprocessing. This is just for us to save the features and data, there is no need for you to see what this is, although you can take a look at them once they're generated.\n",
    "\n",
    "This looks like this:\n",
    "          \n",
    "```python \n",
    "pre.windowing(input_file=[r'Data/data-mok/Gijs_Mok_GH010035-ACCL.csv', r'Data/data-mok/Gijs_Mok_GH010035-GYRO.csv'], # these are the accl and gyro datafiles. It is easiest to put your own data inside the data folder and change the path accordingly.\n",
    "              video_file='Data/data-mok/GL010035_LRV.mp4', # this is the corresponding video file\n",
    "              start_offset = 0, # here you can enter the start ofset for this file\n",
    "              stop_offset = 0, # here you can enter the stop ofset for this file\n",
    "              size = frame_size, # this is done automatically, because you assigned them already\n",
    "              offset = frame_offset) # this is done automatically, because you assigned them already\n",
    "            \n",
    "```\n",
    "The more different files you have, the more times you need to fill this in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "\n",
    "# making the data files for the storage of the data\n",
    "empty_files([f'Preprocessed-data/{Product}/features_{Product}.txt',\n",
    "             f'Preprocessed-data/{Product}/features_{Product}_scaled.csv',\n",
    "             f'Preprocessed-data/{Product}/processed_data_files.txt'])\n",
    "\n",
    "# Make a preprocessing object that corresponds with the product\n",
    "pre = Preprocessing(Product)\n",
    "\n",
    "# Insert the data into the preprocessing object.\n",
    "pre.windowing(input_file=[r'Data/data-mok/Gijs_Mok_GH010035-ACCL.csv', r'Data/data-mok/Gijs_Mok_GH010035-GYRO.csv'],\n",
    "              video_file='Data/data-mok/GL010035_LRV.mp4',\n",
    "              start_offset=0, \n",
    "              stop_offset=0, \n",
    "              size=frame_size,\n",
    "              offset=frame_offset)\n",
    "\n",
    "# example of extra datafile with video (uncomment if needed)\n",
    "\n",
    "'''\n",
    "pre.windowing(input_file=[r'Data/data-mok/Gijs_Mok_GH010036-ACCL.csv', r'Data/data-mok/Gijs_Mok_GH010036-GYRO.csv'],\n",
    "              video_file='Data/data-mok/GL010036_LRV.mp4',\n",
    "              start_offset=0, \n",
    "              stop_offset=0, \n",
    "              size=frame_size,\n",
    "              offset=frame_offset)\n",
    "              \n",
    "'''\n",
    "\n",
    "\n",
    "# Initiate the scaler on the preprocessing object, in order to get scaled features.\n",
    "pre.SuperStandardScaler(fr'Preprocessed-data\\{Product}\\features_{Product}.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling and training\n",
    "\n",
    "If you've set up your preprocessing correctly this step should be quite easy. The application will show you part of your recording, and you will be asked to label it according to the action performed on screen. You can add a new label if the Product you see is not one of the options you expected. \n",
    "\n",
    "First, enter the activities that you think will be in the video. Don't worry about doing this too much, you can always add more labels later in the code block below, however if you restart training, these will be lost. To enter a new label enter the new label according to the explananation during labeling, this will add it.\n",
    "\n",
    "An example:\n",
    "```python \n",
    "   labels = ['Still', 'Pick_up', 'Put_down', 'Drinking', 'Walking']\n",
    "   ```\n",
    "\n",
    "\n",
    "Enter your labels inside the code block below. **Only change the text inside the brackets, remember to put the names in quotation marks and separate them by commas**.\n",
    "\n",
    "Next up is training the model. After entering your labels, run cell 6,7 and 8 and you will be shown a part of your own recorded video and asked to label the activity you see. Take your time to label the data correctly, as the results fully rely on accurate labels. You get the option to delete a data point if you are not completely sure about the label (\"x\") e.g. the sample contains two different actions or if it's a faulty sample. \n",
    "\n",
    "The value of 'active_learning_iterations', is the amount of samples you will label. The more samples you label, the more accurate the model might become, but the more time it will consume. Labeling round 10-20% of the total amount of samples or at least 100 samples is advised for a good model (enter this in `active_learning_iterations`). The cell below can be used to find the amount of available samples.\n",
    "\n",
    "After labeling 16 samples, an image with the labeled frames will show, this is so you can see the data in perspective, the image shown is a PCA anaysis. Also the model will have its first version, so the probabilities of the class according to the model is shown. This does not mean that the model is right! you still need to enter your answer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    }
   ],
   "source": [
    "# 6\n",
    "\n",
    "# This code shows you the amount of datapoints you have for the active learning.\n",
    "print(amount_of_samples(f'Preprocessed-data/{Product}/processed_data_files.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7\n",
    "\n",
    "# Here you can put the labels of the activities that you think are goin to be in the video. You can always add later.\n",
    "labels = ['Still', 'Pick_up', 'Put_down', 'Drinking', 'Walking']\n",
    "\n",
    "# this is the ammount of iterations that it will use for the active learning, see text for more context\n",
    "active_learning_iterations = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8\n",
    "\n",
    "# No need for any modification here, just run it.\n",
    "AL = ActiveLearning(fr'Preprocessed-data/{Product}/features_{Product}_scaled.csv', Product, labels, frame_size)\n",
    "labels = AL.training(active_learning_iterations, random_points=1)\n",
    "AL.write_to_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get an idea of how accurate the model is, it is advised to label some more data. These frames are not used in training the model, but the model is used to predict the action that is happening in this frame. By telling the model which action actually is happening in the frame, the accuracy can be measured, by calculating the error rate (dividing the wrong labled frames by the total amount of frames). It is advised to label at least 20 frames, but preferably more (about 50). The more frames are labled, the better the indication of the accuracy is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9\n",
    "\n",
    "# start the testing and enter how many tests you want to run in the brackets.\n",
    "AL.testing(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <head>\n",
       "                    <script type=\"text/javascript\">\n",
       "                    let id = 0;\n",
       "                    const time_video = [[10.0, 'Data/data-mok/GL010035_LRV.mp4'], [1.5000000000000002, 'Data/data-mok/GL010035_LRV.mp4'], [1.7000000000000004, 'Data/data-mok/GL010035_LRV.mp4'], [1.8000000000000005, 'Data/data-mok/GL010035_LRV.mp4'], [2.0000000000000004, 'Data/data-mok/GL010035_LRV.mp4'], [2.500000000000001, 'Data/data-mok/GL010035_LRV.mp4'], [3.1000000000000014, 'Data/data-mok/GL010035_LRV.mp4'], [3.3000000000000016, 'Data/data-mok/GL010035_LRV.mp4'], [3.4000000000000017, 'Data/data-mok/GL010035_LRV.mp4'], [5.299999999999997, 'Data/data-mok/GL010035_LRV.mp4'], [5.399999999999997, 'Data/data-mok/GL010035_LRV.mp4'], [5.4999999999999964, 'Data/data-mok/GL010035_LRV.mp4'], [5.599999999999996, 'Data/data-mok/GL010035_LRV.mp4'], [5.699999999999996, 'Data/data-mok/GL010035_LRV.mp4'], [6.099999999999994, 'Data/data-mok/GL010035_LRV.mp4'], [6.199999999999994, 'Data/data-mok/GL010035_LRV.mp4'], [7.999999999999988, 'Data/data-mok/GL010035_LRV.mp4'], [9.299999999999985, 'Data/data-mok/GL010035_LRV.mp4'], [9.399999999999984, 'Data/data-mok/GL010035_LRV.mp4'], [10.09999999999998, 'Data/data-mok/GL010035_LRV.mp4'], [10.29999999999998, 'Data/data-mok/GL010035_LRV.mp4'], [10.39999999999998, 'Data/data-mok/GL010035_LRV.mp4'], [10.599999999999978, 'Data/data-mok/GL010035_LRV.mp4'], [10.799999999999978, 'Data/data-mok/GL010035_LRV.mp4'], [17.199999999999974, 'Data/data-mok/GL010035_LRV.mp4'], [17.49999999999998, 'Data/data-mok/GL010035_LRV.mp4'], [17.59999999999998, 'Data/data-mok/GL010035_LRV.mp4'], [18.39999999999999, 'Data/data-mok/GL010035_LRV.mp4'], [18.9, 'Data/data-mok/GL010035_LRV.mp4'], [19.500000000000007, 'Data/data-mok/GL010035_LRV.mp4'], [19.70000000000001, 'Data/data-mok/GL010035_LRV.mp4'], [24.100000000000072, 'Data/data-mok/GL010035_LRV.mp4'], [24.200000000000077, 'Data/data-mok/GL010035_LRV.mp4'], [24.300000000000075, 'Data/data-mok/GL010035_LRV.mp4'], [24.40000000000008, 'Data/data-mok/GL010035_LRV.mp4'], [24.60000000000008, 'Data/data-mok/GL010035_LRV.mp4'], [24.80000000000008, 'Data/data-mok/GL010035_LRV.mp4'], [25.000000000000085, 'Data/data-mok/GL010035_LRV.mp4'], [25.30000000000009, 'Data/data-mok/GL010035_LRV.mp4'], [26.70000000000011, 'Data/data-mok/GL010035_LRV.mp4'], [26.80000000000011, 'Data/data-mok/GL010035_LRV.mp4'], [27.800000000000125, 'Data/data-mok/GL010035_LRV.mp4'], [27.900000000000126, 'Data/data-mok/GL010035_LRV.mp4'], [28.600000000000136, 'Data/data-mok/GL010035_LRV.mp4'], [28.80000000000014, 'Data/data-mok/GL010035_LRV.mp4'], [29.100000000000144, 'Data/data-mok/GL010035_LRV.mp4'], [31.900000000000183, 'Data/data-mok/GL010035_LRV.mp4'], [32.000000000000185, 'Data/data-mok/GL010035_LRV.mp4'], [32.30000000000019, 'Data/data-mok/GL010035_LRV.mp4'], [34.800000000000225, 'Data/data-mok/GL010035_LRV.mp4'], [35.30000000000023, 'Data/data-mok/GL010035_LRV.mp4'], [35.500000000000234, 'Data/data-mok/GL010035_LRV.mp4'], [35.60000000000024, 'Data/data-mok/GL010035_LRV.mp4'], [35.70000000000024, 'Data/data-mok/GL010035_LRV.mp4'], [35.80000000000024, 'Data/data-mok/GL010035_LRV.mp4'], [36.40000000000025, 'Data/data-mok/GL010035_LRV.mp4'], [37.000000000000256, 'Data/data-mok/GL010035_LRV.mp4'], [37.10000000000026, 'Data/data-mok/GL010035_LRV.mp4'], [37.20000000000026, 'Data/data-mok/GL010035_LRV.mp4'], [37.30000000000026, 'Data/data-mok/GL010035_LRV.mp4'], [37.50000000000026, 'Data/data-mok/GL010035_LRV.mp4'], [37.60000000000026, 'Data/data-mok/GL010035_LRV.mp4'], [37.700000000000266, 'Data/data-mok/GL010035_LRV.mp4'], [37.80000000000027, 'Data/data-mok/GL010035_LRV.mp4'], [37.90000000000027, 'Data/data-mok/GL010035_LRV.mp4'], [38.00000000000027, 'Data/data-mok/GL010035_LRV.mp4'], [38.10000000000027, 'Data/data-mok/GL010035_LRV.mp4'], [38.90000000000028, 'Data/data-mok/GL010035_LRV.mp4'], [40.80000000000031, 'Data/data-mok/GL010035_LRV.mp4'], [40.90000000000031, 'Data/data-mok/GL010035_LRV.mp4'], [41.00000000000031, 'Data/data-mok/GL010035_LRV.mp4'], [41.900000000000325, 'Data/data-mok/GL010035_LRV.mp4'], [50.400000000000446, 'Data/data-mok/GL010035_LRV.mp4'], [52.10000000000047, 'Data/data-mok/GL010035_LRV.mp4'], [54.1000000000005, 'Data/data-mok/GL010035_LRV.mp4'], [55.50000000000052, 'Data/data-mok/GL010035_LRV.mp4'], [55.90000000000053, 'Data/data-mok/GL010035_LRV.mp4'], [59.20000000000057, 'Data/data-mok/GL010035_LRV.mp4'], [59.30000000000057, 'Data/data-mok/GL010035_LRV.mp4'], [59.400000000000574, 'Data/data-mok/GL010035_LRV.mp4'], [59.500000000000576, 'Data/data-mok/GL010035_LRV.mp4'], [60.00000000000058, 'Data/data-mok/GL010035_LRV.mp4'], [60.10000000000058, 'Data/data-mok/GL010035_LRV.mp4'], [64.10000000000063, 'Data/data-mok/GL010035_LRV.mp4'], [67.00000000000047, 'Data/data-mok/GL010035_LRV.mp4'], [68.1000000000004, 'Data/data-mok/GL010035_LRV.mp4'], [72.10000000000018, 'Data/data-mok/GL010035_LRV.mp4'], [73.20000000000012, 'Data/data-mok/GL010035_LRV.mp4'], [75.00000000000001, 'Data/data-mok/GL010035_LRV.mp4'], [76.09999999999995, 'Data/data-mok/GL010035_LRV.mp4'], [76.19999999999995, 'Data/data-mok/GL010035_LRV.mp4'], [77.99999999999984, 'Data/data-mok/GL010035_LRV.mp4'], [80.79999999999968, 'Data/data-mok/GL010035_LRV.mp4'], [89.09999999999921, 'Data/data-mok/GL010035_LRV.mp4'], [91.79999999999906, 'Data/data-mok/GL010035_LRV.mp4'], [92.599999999999, 'Data/data-mok/GL010035_LRV.mp4'], [93.29999999999896, 'Data/data-mok/GL010035_LRV.mp4'], [93.39999999999895, 'Data/data-mok/GL010035_LRV.mp4'], [93.49999999999896, 'Data/data-mok/GL010035_LRV.mp4'], [93.89999999999894, 'Data/data-mok/GL010035_LRV.mp4'], [93.99999999999892, 'Data/data-mok/GL010035_LRV.mp4'], [94.39999999999893, 'Data/data-mok/GL010035_LRV.mp4'], [100.29999999999858, 'Data/data-mok/GL010035_LRV.mp4'], [100.69999999999855, 'Data/data-mok/GL010035_LRV.mp4'], [101.5999999999985, 'Data/data-mok/GL010035_LRV.mp4'], [101.79999999999848, 'Data/data-mok/GL010035_LRV.mp4'], [103.69999999999838, 'Data/data-mok/GL010035_LRV.mp4'], [104.39999999999834, 'Data/data-mok/GL010035_LRV.mp4'], [104.99999999999832, 'Data/data-mok/GL010035_LRV.mp4'], [114.1999999999978, 'Data/data-mok/GL010035_LRV.mp4'], [114.49999999999775, 'Data/data-mok/GL010035_LRV.mp4'], [115.29999999999772, 'Data/data-mok/GL010035_LRV.mp4'], [115.49999999999773, 'Data/data-mok/GL010035_LRV.mp4'], [115.99999999999768, 'Data/data-mok/GL010035_LRV.mp4'], [116.09999999999768, 'Data/data-mok/GL010035_LRV.mp4'], [117.09999999999762, 'Data/data-mok/GL010035_LRV.mp4'], [117.3999999999976, 'Data/data-mok/GL010035_LRV.mp4'], [118.49999999999754, 'Data/data-mok/GL010035_LRV.mp4'], [118.79999999999752, 'Data/data-mok/GL010035_LRV.mp4'], [119.1999999999975, 'Data/data-mok/GL010035_LRV.mp4'], [122.19999999999732, 'Data/data-mok/GL010035_LRV.mp4'], [126.2999999999971, 'Data/data-mok/GL010035_LRV.mp4'], [129.39999999999694, 'Data/data-mok/GL010035_LRV.mp4'], [135.0999999999966, 'Data/data-mok/GL010035_LRV.mp4'], [137.69999999999646, 'Data/data-mok/GL010035_LRV.mp4'], [137.89999999999645, 'Data/data-mok/GL010035_LRV.mp4'], [138.19999999999644, 'Data/data-mok/GL010035_LRV.mp4'], [139.49999999999636, 'Data/data-mok/GL010035_LRV.mp4'], [142.2999999999962, 'Data/data-mok/GL010035_LRV.mp4'], [144.99999999999605, 'Data/data-mok/GL010035_LRV.mp4'], [145.19999999999604, 'Data/data-mok/GL010035_LRV.mp4'], [148.79999999999583, 'Data/data-mok/GL010035_LRV.mp4'], [149.09999999999582, 'Data/data-mok/GL010035_LRV.mp4'], [153.29999999999558, 'Data/data-mok/GL010035_LRV.mp4'], [153.69999999999555, 'Data/data-mok/GL010035_LRV.mp4'], [155.69999999999544, 'Data/data-mok/GL010035_LRV.mp4'], [157.29999999999535, 'Data/data-mok/GL010035_LRV.mp4'], [158.99999999999525, 'Data/data-mok/GL010035_LRV.mp4'], [160.59999999999516, 'Data/data-mok/GL010035_LRV.mp4'], [160.69999999999516, 'Data/data-mok/GL010035_LRV.mp4'], [168.4999999999947, 'Data/data-mok/GL010035_LRV.mp4'], [171.09999999999457, 'Data/data-mok/GL010035_LRV.mp4'], [171.19999999999456, 'Data/data-mok/GL010035_LRV.mp4'], [171.39999999999455, 'Data/data-mok/GL010035_LRV.mp4'], [175.39999999999432, 'Data/data-mok/GL010035_LRV.mp4'], [175.5999999999943, 'Data/data-mok/GL010035_LRV.mp4'], [175.6999999999943, 'Data/data-mok/GL010035_LRV.mp4'], [179.2999999999941, 'Data/data-mok/GL010035_LRV.mp4'], [180.39999999999404, 'Data/data-mok/GL010035_LRV.mp4'], [181.89999999999395, 'Data/data-mok/GL010035_LRV.mp4'], [183.49999999999383, 'Data/data-mok/GL010035_LRV.mp4'], [189.09999999999357, 'Data/data-mok/GL010035_LRV.mp4']];\n",
       "                    let time = time_video[0][0];\n",
       "                    const ws = 0.7;\n",
       "\n",
       "                    function init_670() {\n",
       "                        let video = document.getElementById(\"nov_670\");\n",
       "                        video.currentTime = time;\n",
       "                        play_670();\n",
       "                    }\n",
       "\n",
       "                    function play_670() {\n",
       "                        let video = document.getElementById(\"nov_670\");\n",
       "                        if (video.currentTime < time || video.currentTime >= time + ws) {\n",
       "                            video.currentTime = time;\n",
       "                        }\n",
       "                        video.play();\n",
       "                        setInterval(function () {\n",
       "                            if (video.currentTime >= time + ws) {\n",
       "                                video.currentTime = time;\n",
       "                            }\n",
       "                        }, 1);\n",
       "                    }\n",
       "\n",
       "                    function pause_670() {\n",
       "                        let video = document.getElementById(\"nov_670\");\n",
       "                        video.pause();\n",
       "                    }\n",
       "\n",
       "                    function prev_670() {\n",
       "                    if (id >= 0) {\n",
       "                            id = id - 1;\n",
       "                            time = time_video[id][0];\n",
       "                            let video = document.getElementById(\"nov_670\");\n",
       "                            video.setAttribute('src', time_video[id][1]);\n",
       "                            document.getElementById(\"content\").innerHTML = 'Novelty ' + (id + 1) + ' out of 152 at ' + time + 's in ' + time_video[id][1];\n",
       "                            play_670();\n",
       "                        }\n",
       "                    }\n",
       "\n",
       "                    function next_670() {\n",
       "                        if (id < 152 - 1) {\n",
       "                            id = id + 1;\n",
       "                            time = time_video[id][0];\n",
       "                            let video = document.getElementById(\"nov_670\");\n",
       "                            video.setAttribute('src', time_video[id][1]);\n",
       "                            document.getElementById(\"content\").innerHTML = 'Novelty ' + (id + 1) + ' out of 152 at ' + time + 's in ' + time_video[id][1];\n",
       "                            play_670();\n",
       "                        }\n",
       "                    }\n",
       "\n",
       "                    </script>\n",
       "                    <title></title>\n",
       "                </head>\n",
       "                <body>\n",
       "                    <video id=\"nov_670\" height=\"300px\" src=\"Data/data-mok/GL010035_LRV.mp4\" muted></video>\n",
       "                    <br>\n",
       "                    <script type=\"text/javascript\">init_670()</script>\n",
       "                    <button onClick=\"play_670()\">Play</button>\n",
       "                    <button onClick=\"pause_670()\">Pause</button>\n",
       "                    <button onClick=\"prev_670()\">Previous novelty</button>\n",
       "                    <button onClick=\"next_670()\">Next novelty</button>\n",
       "                    <div id=\"content\">Novelty 1 out of 152 at 10.0s in Data/data-mok/GL010035_LRV.mp4</div>\n",
       "                </body>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#10\n",
    "\n",
    "# No need to change anything here.\n",
    "# Detect the noveties\n",
    "ND = NoveltyDetection(fr'Preprocessed-data/{Product}/features_{Product}_scaled_AL_predictionss.csv', fr'Preprocessed-data/{Product}/processed_data_files.txt')\n",
    "novelties = ND.detect(0.1)\n",
    "novelties[0][0] = 10.0\n",
    "\n",
    "# Display the novelties\n",
    "ND.play_novelties(novelties, frame_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information about your data\n",
    "\n",
    "To get more information about your data, please run the cell below to see a timeline with the classified actions. \n",
    "Do notice that if you have multiple files, they are stitched together in one timeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11\n",
    "\n",
    "# Print and generate some statistics about the product usage for analysis.\n",
    "stats = Stats(fr'Preprocessed-data/{Product}/features_{Product}_scaled_AL_predictionss.csv', labels)\n",
    "stats.print_percentages()\n",
    "stats.show_ghan_chart(frame_offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Data\n",
    "\n",
    "In the section beneath we will quickly run through some of the same steps as above, but now we can feed the model that we created with new, unseen data. The model created in the steps above will be used to predict the actions happening in this unseen data. This can be helpful for testing the robustness of your model when data was gathered by different people. \n",
    "\n",
    "Moreover, this is the step where you can enter data that has not been gathered in a controlled environment, but real life data, for you to analyse real product usage and not what you thought was going to happen.\n",
    "\n",
    "Now you can feed the trained model more data by changing the 'pre_new.windowing' function!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "empty_files([f'Preprocessed-data/{Product}_new/features_{Product}_new.txt',\n",
    "             f'Preprocessed-data/{Product}_new/features_{Product}_new_scaled.csv',\n",
    "             f'Preprocessed-data/{Product}_new/processed_data_files.txt'])\n",
    "\n",
    "# Load the model that you made using pickle\n",
    "model = pickle.load(open(fr'Models/model_{Product}_{active_learning_iterations}.pickle', 'rb'))\n",
    "\n",
    "# Preprocess the new data\n",
    "pre_new = Preprocessing(f'{Product}_new')\n",
    "pre_new.windowing([r'GoPro\\Gijs_Mok\\Gijs_Mok_GH010035-ACCL.csv', r'GoPro\\Gijs_Mok\\Gijs_Mok_GH010035-GYRO.csv'], \n",
    "                    'GoPro\\Gijs_Mok\\GL010035_LRV.mp4',\n",
    "                    start_offset=0, \n",
    "                    stop_offset=0, \n",
    "                    size=frame_size, \n",
    "                    offset=frame_offset, \n",
    "                    epsilon=0.01, \n",
    "                    do_plot=False, \n",
    "                    do_scale=True)\n",
    "\n",
    "# Predict the label of all samples based on the \n",
    "new_dataset = pd.read_csv(fr'Preprocessed-data/{Product}_new/features_{Product}_new_scaled.csv', delimiter=',')\n",
    "predictions = model.predict(np.array(new_dataset.iloc[:, 3:]))\n",
    "\n",
    "# Replace the labels and write them to a new AL prediction file\n",
    "new_dataset['label'] = predictions\n",
    "new_dataset.to_csv(fr'Preprocessed-data/{Product}_new/features_{Product}_new_scaled_AL_predictionss.csv', index=False)\n",
    "\n",
    "# Novelty detection for the new set\n",
    "ND2 = NoveltyDetection(fr'Preprocessed-data/{Product}_new/features_{Product}_new_scaled_AL_predictionss.csv', fr'Preprocessed-data/{Product}_new/processed_data_files.txt')\n",
    "novelties = ND2.detect(0.1)\n",
    "ND2.play_novelties(novelties, frame_size)\n",
    "\n",
    "# Use the new file to retrieve the predicted timeline\n",
    "stats = Stats(fr'Preprocessed-data/{Product}_new/features_{Product}_new_scaled_AL_predictionss.csv', labels)\n",
    "stats.print_percentages()\n",
    "stats.show_ghan_chart(frame_offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor de zekerheid ff een trashbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre.windowing([r\"Data/data-lopen/Walking_part_1.csv\", r\"Data/data-lopen/Walking_part_1_gyro.csv\"], r\"Data/data-lopen/Walking_part_1.mp4\",\n",
    "#               start_offset=2.5, stop_offset=5, size=1, offset=0.2, video_offset=2.5, epsilon=0.01, do_plot=False, do_scale=False)\n",
    "# pre.windowing([r\"Data/data-lopen/Walking_part_2.csv\", r\"Data/data-lopen/Walking_part_2_gyro.csv\"], r\"Data/data-lopen/Walking_part_2.mp4\",\n",
    "#               start_offset=2.5, stop_offset=5, size=1, offset=0.2, video_offset=2.5, epsilon=0.01, do_plot=False, do_scale=True)\n",
    "# pre.windowing([fr'Data\\data-cycling\\ACCL\\Timo_fietsen_GH010031-ACCL.csv', fr'Data\\data-cycling\\GYRO\\Timo_fietsen_GH010031-GYRO.csv'], 'Data\\data-cycling\\Fiets_filmpjes\\GL010031_LRV_compressed.mp4',\n",
    "#               start_offset=0, stop_offset=0, size=5, offset=0.5, epsilon=0.01, do_plot=False, do_scale=False)\n",
    "# pre.windowing([fr'Data\\data-cycling\\ACCL\\Timo_fietsen_GH010032-ACCL.csv', fr'Data\\data-cycling\\GYRO\\Timo_fietsen_GH010032-GYRO.csv'], 'Data\\data-cycling\\Fiets_filmpjes\\GL010032_LRV.mp4',\n",
    "#               start_offset=0, stop_offset=0, size=5, offset=0.5, epsilon=0.01, do_plot=False, do_scale=False)\n",
    "# pre.windowing([fr'Data\\data-cycling\\ACCL\\Timo_fietsen_GH010033-ACCL.csv', fr'Data\\data-cycling\\GYRO\\Timo_fietsen_GH010033-GYRO.csv'], 'Data\\data-cycling\\Fiets_filmpjes\\GL010033_LRV.mp4',\n",
    "#               start_offset=0, stop_offset=0, size=5, offset=0.5, epsilon=0.01, do_plot=False, do_scale=False)\n",
    "# pre.windowing([fr'Data\\data-cycling\\ACCL\\Timo_fietsen_GH010034-ACCL.csv', fr'Data\\data-cycling\\GYRO\\Timo_fietsen_GH010034-GYRO.csv'], 'Data\\data-cycling\\Fiets_filmpjes\\GL010034_LRV_compressed.mp4',\n",
    "#               start_offset=0, stop_offset=0, size=5, offset=0.5, epsilon=0.01, do_plot=False, do_scale=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "529ecdcae69add5700b168af870c2c245dc5754f1a82655f7b34366657b0a28f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
